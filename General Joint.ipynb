{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ed5ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "import matplotlib\n",
    "import pyLikelihood\n",
    "import os\n",
    "import glob \n",
    "from fermipy.gtanalysis import GTAnalysis\n",
    "from fermipy.plotting import ROIPlotter, SEDPlotter\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import brentq\n",
    "from scipy.optimize import minimize_scalar\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline\n",
    "from scipy import interpolate\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from fermipy import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e885e12",
   "metadata": {},
   "source": [
    "## 1- Importando os dados de maneira inteligente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe4dd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vou utilizar dados de P8R2 para 6 e 14 anos\n",
    "list_lnl_14years_P8R2 = glob.glob('eflux_and_loglikes_files/P8R2_14Years_files/*_Dloglikes_14years_P8R2.txt')\n",
    "list_lnl_6years_P8R2 = glob.glob('eflux_and_loglikes_files/P8R2_6years_Files/*_Dloglikes_6years_P8R2.txt')\n",
    "\n",
    "#-----------------------------------------#\n",
    "list_eflux_14years_P8R2 = glob.glob('eflux_and_loglikes_files/P8R2_14Years_files/*_eflux_14years_P8R2.txt')\n",
    "list_eflux_6years_P8R2  = glob.glob('eflux_and_loglikes_files/P8R2_6years_Files/*_eflux_6years_P8R2.txt*')\n",
    "\n",
    "#criando lista de Jfactor\n",
    "\n",
    "Jfactor_array = np.array([18.2,17.6,17.9,19.0,18.8,17.8,16.9,18.0,16.3,18.5,19.4,17.5,19.4,18.9,18.9])\n",
    "\n",
    "# criando Lista de likefiles\n",
    "list_likefile = glob.glob('likes_files/like_*')\n",
    "\n",
    "# Demais dados\n",
    "specfile = 'spectrum_bbbar_100GeV.txt' # Esse txt conseguir em um dos primeiros artigos do fermi\n",
    "crossesctions = np.loadtxt('limits_bb.txt',unpack=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7d11f",
   "metadata": {},
   "source": [
    "### 1.1 Definindo variaveis para funcionalidade do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5350f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(list_likefile[0], unpack=True)\n",
    "emins, emaxs = np.unique(data[0]),np.unique(data[1])\n",
    "ebin = np.sqrt(emins*emaxs)\n",
    "efluxes = data[2].reshape(len(emins),-1)\n",
    "logLikes = data[3].reshape(len(emins),-1)\n",
    "Spectrum =np.loadtxt(specfile,unpack=True)\n",
    "mass = crossesctions[0]\n",
    "sigmav0 = 1e-25\n",
    "delta =2.71\n",
    "\n",
    "lista_de_nomes = ['Bootes','Canes_Venatici II','Carina','Coma_Berenices','Draco',\n",
    "                  'Fornax','Hercules','Leo_II','Leo_IV','Sculptor','Segue_I','Sextans',\n",
    "                  'Ursa_Major_II','Ursa Minor','Willma_1']  \n",
    "\n",
    "lista_de_nomes_old = ['Bootes_I','Canes','Carina', 'Coma','Draco','Fornax','Hercules','Leo_II','Leo_IV','Sculptor','Segue_1',\n",
    "                     'Sextans','Ursa_Major_II','Ursa_Minor','Wilma']\n",
    "# Esse norm_scan é meio artistico de conseguir reproduzi-lo\n",
    "norm_scan = np.loadtxt('norm_scan.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d34ec32",
   "metadata": {},
   "source": [
    "# Estrutura física do códido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f686061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eflux(spectrum, emin=1e2, emax=1e5, quiet=False):\n",
    "    \"\"\" Integrate a generic spectrum, multiplied by E, to get the energy flux.\n",
    "    \"\"\"\n",
    "    espectrum = lambda e: spectrum(e)*e\n",
    "    tol = min(espectrum(emin),espectrum(emax))*1e-10\n",
    "    try:\n",
    "        return quad(espectrum,emin,emax,epsabs=tol,full_output=True)[0]\n",
    "    except (Exception, msg):\n",
    "        print('Numerical error \"%s\" when calculating integral flux.' % msg)\n",
    "        return np.nan\n",
    "# Keep numpy from complaining about dN/dE = 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d98f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Jfactor_array)):\n",
    "    efluxes= np.loadtxt(list_eflux_6years_P8R2[i])\n",
    "    dlog= np.loadtxt(list_lnl_6years_P8R2[i])\n",
    "    lnl_fermi_scan = np.zeros((21,7000))\n",
    "    jfactor_fermi   = Jfactor_array[i]\n",
    "    j0_fermi      = jfactor_fermi\n",
    "    k=0\n",
    "    for m in mass:\n",
    "        dmf = pyLikelihood.DMFitFunction()\n",
    "        dmf.readFunction(os.path.expandvars('$FERMIPY_ROOT/data/gammamc_dif.dat'))\n",
    "        dmf.setParam('norm',10**Jfactor_array[i])\n",
    "        dmf.setParam('sigmav',1E-25)\n",
    "        dmf.setParam('mass',m)\n",
    "        dmf.setParam('bratio',1.0)\n",
    "        dmf.setParam('channel0',4)\n",
    "    \n",
    "        energy = Spectrum[0] \n",
    "        dnde = np.zeros(energy.shape)\n",
    "        for j in range(len(energy)):\n",
    "            dnde[j] = dmf(pyLikelihood.dArg(energy[j]))\n",
    "        \n",
    "        log_energy = np.log10(energy)# Transforma energia para log\n",
    "        log_dnde = np.log10(dnde)# Transforma Espectro para log\n",
    "        log_interp = interp1d(log_energy,log_dnde) # Cria função de Interpolação entre energia e espectro\n",
    "        spectrum = lambda e: np.nan_to_num(10**( log_interp(np.log10(e)) ))# Retorna um Valor de dn/de para um valor de energia\n",
    "    \n",
    "        #print(eflux.shape,dlog.shape)\n",
    "        pred = np.array([eflux(spectrum,e1,e2) for e1,e2 in zip(emins,emaxs)])  # Retorna o Eflux esperado por Bin\n",
    "        likes = [ interp1d(f,l-l.max(), fill_value='extrapolate') for f,l in zip(efluxes,dlog)] \n",
    "        like = lambda c: sum([lnlfn(c*p) for lnlfn,p in zip(likes,pred)])\n",
    "    \n",
    "        norms = norm_scan[k]\n",
    "    \n",
    "        lnl_fermi = np.array([like(n) for n in norms])\n",
    "        lnl_fermi_scan[k] =lnl_fermi\n",
    "        lnl_fermi_normalizada = lnl_fermi -lnl_fermi.max()\n",
    "    \n",
    "        print(lnl_fermi_normalizada.shape, m)\n",
    "        sigmav = j0_fermi/jfactor_fermi * sigmav0 * norms\n",
    "        #crossection_scan_P8R3[k] =sigmav\n",
    "        mle = np.argmax(lnl_fermi_normalizada)\n",
    "        lnlfn = interp1d(lnl_fermi_normalizada[mle:],sigmav[mle:])\n",
    "        delta = 2.71/2\n",
    "        limit = lnlfn(-delta)\n",
    "        #crossection_mass_P8R3[k] = float(limit)\n",
    "        k= k+1\n",
    "        \n",
    "    np.savetxt('New_cross_and_loglikes_files/Upper_limits_6years_P8R2/lnl_fermi_scan_'+lista_de_nomes[i],lnl_fermi_scan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =plt.figure(figsize=(12,6))\n",
    "#plt.plot(mass,Crossection_P8R2,label= 'six_years_P8R2')\n",
    "#plt.plot(mass,Crossection_P8R3, label = 'six_years_P8R3')\n",
    "plt.plot(mass,crossection_mass_P8R2, label = '14 years P8R2')\n",
    "plt.plot(mass,crossection_mass_P8R3, label = '6 anos ')\n",
    "#plt.plot(mass,crossesctions[36], label = 'Arxiv :1611 - Fermi 2015')\n",
    "#plt.plot(mass,crossection_mass_Fermi, label ='Arxiv :1611 - Fermi 2015 without J factor')\n",
    "plt.xlabel('mass (Gev)')\n",
    "plt.ylabel('Cross Section upper limit at 95%')\n",
    "plt.title('Crossections vs Mass')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.text(2.5e3,1e-24,'Wilma', style='oblique',fontsize='15')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78580e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
